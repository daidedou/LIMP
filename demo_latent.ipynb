{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe3ee637",
   "metadata": {},
   "source": [
    "# 3D Human Body and Deep Learning: Demonstration.\n",
    "\n",
    "This notebook will be dedicated to the exploration of the LIMP method for human shapes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241238a5",
   "metadata": {},
   "source": [
    "### Loading pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b894dfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointNetVAE(\n",
       "  (enc): Encoder(\n",
       "    (ptnet): SimplePointNet(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv1d(32, 128, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (transformers): ModuleList(\n",
       "        (0): SimpleTransformer(\n",
       "          (conv_layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "              (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (fc_layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "              (1): ReLU()\n",
       "            )\n",
       "            (1): Linear(in_features=256, out_features=9, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc_layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec): Decoder(\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=2048, out_features=6300, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from utils_distance import *\n",
    "from models.model import PointNetVAE\n",
    "import trimesh\n",
    "import vtk\n",
    "from vtkviz.vtkVisualization import *\n",
    "# More details here : https://github.com/daidedou/vtkviz/blob/main/vtkVisualization.py\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "device = 'cpu'\n",
    "\n",
    "faust_path = 'C:\\\\Users\\\\Avatar2\\\\Documents\\\\Emery\\\\bdd\\\\MPI-FAUST\\\\training'\n",
    "faust_2500_path = \"C:\\\\Users\\\\Avatar2\\\\Documents\\\\Emery\\\\cours\\\\aida\\\\LIMP\\\\faust\\\\FAUST\"\n",
    "destop_path = \"C:\\\\Users\\\\Avatar2\\\\Desktop\"\n",
    "#model options\n",
    "opt = lambda x:x\n",
    "opt.NUM_POINTS = 2100\n",
    "opt.BATCH_SIZE = 16\n",
    "opt.DESC_SIZE = 512 #pointwise descriptro size after convlolutional layers\n",
    "opt.LATENT_SPACE = 256 #dimension of the full (pose+style) latent space\n",
    "opt.POSE_SIZE = 64 #number of dimension dedicated to pose encoding \n",
    "\n",
    "opt.LOCAL_TH = 0.1\n",
    "opt.LEARNING_RATE = 0.1e-4\n",
    "\n",
    "vae = PointNetVAE(opt).to(device)\n",
    "\n",
    "\n",
    "#load pretrained model\n",
    "net_type = '4'\n",
    "\n",
    "loss_step = '' \n",
    "loss_step = '_ae_euc' \n",
    "loss_step = '_ae_euc_gd1' \n",
    "loss_step = '_ae_euc_gd2' \n",
    "\n",
    "vae.load_state_dict(torch.load('pretrained/FAUST_vae_euc_gd.dict'), strict=False)\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee72ec",
   "metadata": {},
   "source": [
    " ### Human data \n",
    " Let's load some human shapes!\n",
    " \n",
    " First a registered mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0732f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mesh_2500(path):\n",
    "    VERT = np.loadtxt(path+'/mesh.vert')\n",
    "    TRIV = np.loadtxt(path+'/mesh.triv',dtype='int32')-1\n",
    "    return VERT, TRIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d1f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mesh_vtk(mesh):\n",
    "    surf_actor = VTKSurface(mesh.vertices, mesh.faces)\n",
    "    renderer = VTKVisualization()\n",
    "    renderer.add_entity(surf_actor)\n",
    "    renderer.init()\n",
    "    ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26809eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa5ce83be6b4866954166d05848dddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh_reg = trimesh.load(os.path.join(faust_path, \"registrations\", \"tr_reg_007.ply\"), process=False)\n",
    "surf_actor = VTKSurface(mesh_reg.vertices, mesh_reg.faces)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "775d7e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ccd93b6ed94e178e084f651da55936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "verts_2500, faces_2500 = load_mesh_2500(os.path.join(faust_2500_path, \"tr_reg_007_2000\"))\n",
    "surf_actor = VTKSurface(verts_2500, faces_2500)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172fd2c",
   "metadata": {},
   "source": [
    "Now let's load the corresponding scan mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a57afeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5144afd55a4f138594ecf212d9231c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh_scan = trimesh.load(os.path.join(faust_path, \"scans\", \"tr_scan_007.ply\"), process=False)\n",
    "surf_actor = VTKSurface(mesh_scan.vertices, mesh_scan.faces)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0567712",
   "metadata": {},
   "source": [
    "### Encoder -> Decoder \n",
    "\n",
    "Let's first observe the effect of the encoding of one mesh. \n",
    "The training configuration of this specific method were with meshes of size 2100 (2100 vertices), so the resolution of the reconstructed mesh will be lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50c1f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(vae, vertices):\n",
    "    vertices[:, 1] -= 0.85 + np.min(vertices[:, 1])\n",
    "    verts_torch = torch.from_numpy(vertices).float().unsqueeze(0).to(device)\n",
    "    lsp = vae.enc(verts_torch)\n",
    "    z_latent = lsp[:, :lsp.shape[1]//2]\n",
    "    return z_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adc614d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_reg = encode(vae, mesh_reg.vertices)\n",
    "z_scan = encode(vae, mesh_scan.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37bb0b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "print(z_reg.shape)\n",
    "print(z_scan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(vae, latent_code):\n",
    "    verts_rec = vae.dec(latent_code)\n",
    "    verts_rec[:, :, 0] *= -1\n",
    "    return verts_rec.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8f94fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9733cb38a6b4d15863d0493e68dde1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "verts_rec_reg = decode(vae, z_reg)\n",
    "surf_actor = VTKSurface(verts_rec_reg, faces_2500)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e19be20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9f260cdd164e03b698e59131c9c0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "verts_rec_scan = decode(vae, z_scan)\n",
    "surf_actor = VTKSurface(verts_rec_scan, faces_2500)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4504e71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251276033759476b8895e1ec65dbd66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh_scan_2 = trimesh.load(os.path.join(faust_path, \"scans\", \"tr_scan_012.ply\"), process=False)\n",
    "surf_actor = VTKSurface(mesh_scan_2.vertices, mesh_scan_2.faces)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eb96bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scan_1 = encode(vae, mesh_scan.vertices)\n",
    "z_scan_2 = encode(vae, mesh_scan_2.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c7b6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_new = (z_scan_1 + z_scan_2)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d38be376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f14413819e471e9a6de1c28dfcdc16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "verts_rec_new = decode(vae, z_new)\n",
    "surf_actor = VTKSurface(verts_rec_new, faces_2500)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1a47cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pose_1, z_shape_1 = z_scan_1[:, :opt.POSE_SIZE], z_scan_1[:, opt.POSE_SIZE:]\n",
    "z_pose_2, z_shape_2 = z_scan_2[:, :opt.POSE_SIZE], z_scan_2[:, opt.POSE_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9814fa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204433f41bb647758ad9ec1015cd6ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#z_new = torch.cat(((z_pose_1+z_pose_2)/2, z_shape_1), axis=1)\n",
    "z_new = torch.cat((z_pose_2, z_shape_1), axis=1)\n",
    "verts_rec_new = decode(vae, z_new)\n",
    "surf_actor = VTKSurface(verts_rec_new, faces_2500)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e8ec4e",
   "metadata": {},
   "source": [
    "### Dealing with noise\n",
    "\n",
    "What is the behavior of our network with noisy shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5912e897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4599e1d85f974d93a065a6c686757f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh_noise = trimesh.load(os.path.join(destop_path, \"cvssp_1.ply\"), process=False)\n",
    "surf_actor = VTKSurface(mesh_noise.vertices, mesh_noise.faces)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c9f1564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e978736a9946ed91e0485289b8c6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=800, layout=Layout(height='auto', width='100%'), width=1200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_noise = encode(vae, mesh_noise.vertices)\n",
    "verts_rec_noise = decode(vae, z_noise)\n",
    "surf_actor = VTKSurface(verts_rec_noise, faces_2500)\n",
    "renderer = VTKVisualization()\n",
    "renderer.add_entity(surf_actor)\n",
    "renderer.init()\n",
    "ViewInteractiveWidget(renderer.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426fd728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
